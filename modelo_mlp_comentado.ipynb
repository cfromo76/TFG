{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952cfe13",
   "metadata": {},
   "source": [
    "# Modelo MLP con comentarios detallados\n",
    "Este cuaderno entrena un modelo de red neuronal para detectar influencia en la conducción basándose en el acta de signos externos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modelo MLP para la detección de la influencia en la conducción por consumo de drogas,\n",
    "basado en el acta de signos externos. Este código forma parte del Trabajo Fin de Grado\n",
    "del Grado en Ingeniería Informática, siguiendo los criterios de la UNIR.\n",
    "\"\"\"\n",
    "\n",
    "# Importamos las librerías necesarias para el tratamiento de datos, modelado y evaluación\n",
    "import pandas as pd  # Para manejo de datos tabulares (CSV)\n",
    "from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba\n",
    "from sklearn.preprocessing import StandardScaler  # Para normalizar variables numéricas\n",
    "from sklearn.neural_network import MLPClassifier  # Para construir el perceptrón multicapa (MLP)\n",
    "from sklearn.metrics import classification_report, confusion_matrix  # Para evaluar el modelo\n",
    "\n",
    "# === CARGA DE DATOS ===\n",
    "# Cargamos el dataset generado a partir del acta de signos externos.\n",
    "# Este archivo debe estar en la misma carpeta que este script.\n",
    "df = pd.read_csv(\"dataset_acta_extendido_realista_1000.csv\", sep=\";\")\n",
    "\n",
    "# === SEPARACIÓN DE VARIABLES ===\n",
    "# X contendrá las variables predictoras (signos clínicos y comportamentales)\n",
    "# y contendrá la variable objetivo: influencia (1 = influenciado, 0 = no influenciado)\n",
    "X = df.drop(columns=[\"influencia\"])\n",
    "y = df[\"influencia\"]\n",
    "\n",
    "# === PREPROCESAMIENTO ===\n",
    "# Normalizamos únicamente la variable continua del diámetro pupilar,\n",
    "# ya que las demás son binarias (0/1) y no requieren escalado.\n",
    "scaler = StandardScaler()\n",
    "X[\"G_diametro_pupilar_ambos_ojos_presentan\"] = scaler.fit_transform(\n",
    "    X[[\"G_diametro_pupilar_ambos_ojos_presentan\"]]\n",
    ")\n",
    "\n",
    "# === DIVISIÓN DEL DATASET ===\n",
    "# Estratificamos según la variable 'influencia' para mantener la proporción de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# === DEFINICIÓN Y ENTRENAMIENTO DEL MODELO MLP ===\n",
    "# Creamos un perceptrón multicapa con dos capas ocultas:\n",
    "# - 64 neuronas en la primera capa\n",
    "# - 32 neuronas en la segunda capa\n",
    "# La función de activación es ReLU y el entrenamiento se limita a 1000 iteraciones.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)  # Entrenamos el modelo con los datos de entrenamiento\n",
    "\n",
    "# === EVALUACIÓN DEL MODELO ===\n",
    "# Evaluamos el modelo con los datos de prueba.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Mostramos la matriz de confusión y un informe detallado de precisión, recall y F1-score\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
